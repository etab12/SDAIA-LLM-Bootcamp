{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlGpLgIaxp9z"
      },
      "source": [
        "#Hate Speech Detection with AraBERT and HuggingFace\n",
        "In this assignment, we will be exploring the application of the AraBERT model specifically for the task of hate speech detection. We will use the AJGT Sentiment Analysis dataset from K. M. Alomari, H. M. ElSherif, and K. Shaalan, “Arabic tweets sentimental analysis using machine learning,” in Proceedings of the International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, pp. 602–610, Montreal, Canada, June 2017.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JwOAlV5xsGV"
      },
      "source": [
        "# Check which GPU we have"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krFwQr32xqLv",
        "outputId": "e21b808b-81ed-424a-90b5-7ba85ab623e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    !nvidia-smi\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Wed Jan 24 22:45:44 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8              11W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd6vAHTei6PQ"
      },
      "source": [
        "##Installing Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohWiDLEnxJA5",
        "outputId": "c86fe682-9edb-40c0-e7d5-e6828d9bfe56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install farasapy\n",
        "!pip install pyarabic\n",
        "!git clone https://github.com/aub-mind/arabert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.26.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: farasapy in /usr/local/lib/python3.10/dist-packages (0.0.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2023.11.17)\n",
            "Requirement already satisfied: pyarabic in /usr/local/lib/python3.10/dist-packages (0.6.15)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from pyarabic) (1.16.0)\n",
            "fatal: destination path 'arabert' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFxAnGMIx1qG"
      },
      "source": [
        "#Reading Data\n",
        "We will rely on the following libraries for training and evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl-z0SH0gR_C"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/komari6/Arabic-twitter-corpus-AJGT.git"
      ],
      "metadata": {
        "id": "VBYk072elB84",
        "outputId": "ccf97ffc-cf9c-419c-fc94-48f63b930eba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Arabic-twitter-corpus-AJGT' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Arabic-twitter-corpus-AJGT"
      ],
      "metadata": {
        "id": "CyyUgkjGh79l",
        "outputId": "fc57d078-918f-4380-d919-23513fb7b4fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AJGT.xlsx  LICENSE.md  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1:** Read the dataset and arrange the columns name using the set variables:"
      ],
      "metadata": {
        "id": "8T1UM7HcoQkm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKFr-GcJjXEE",
        "outputId": "2cd00b77-d07d-4a5b-8f41-4b2f1d80a09b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "dataset= pd.read_excel('Arabic-twitter-corpus-AJGT/AJGT.xlsx')\n",
        "\n",
        "DATA_COLUMN = 'text'\n",
        "LABEL_COLUMN = 'labels'\n",
        "dataset=dataset[['Feed' , 'Sentiment']]\n",
        "dataset.columns = [DATA_COLUMN, LABEL_COLUMN]\n",
        "dataset.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text    labels\n",
              "0   اربد فيها جامعات اكثر من عمان ... وفيها قد عم...  Positive\n",
              "1   الحلو انكم بتحكوا على اساس انو الاردن ما فيه ...  Negative\n",
              "2                            كله رائع بجد ربنا يكرمك  Positive\n",
              "3                                 لسانك قذر يا قمامه  Negative\n",
              "4  ​انا داشره وغير متزوجه ولدي علاقات مشبوه واحشش...  Negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b22760b-a341-4854-8a89-fbd1ddd99822\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>اربد فيها جامعات اكثر من عمان ... وفيها قد عم...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>الحلو انكم بتحكوا على اساس انو الاردن ما فيه ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>كله رائع بجد ربنا يكرمك</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>لسانك قذر يا قمامه</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>​انا داشره وغير متزوجه ولدي علاقات مشبوه واحشش...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b22760b-a341-4854-8a89-fbd1ddd99822')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b22760b-a341-4854-8a89-fbd1ddd99822 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b22760b-a341-4854-8a89-fbd1ddd99822');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fa5adc16-55d2-4143-8810-28e3927df5c6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa5adc16-55d2-4143-8810-28e3927df5c6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fa5adc16-55d2-4143-8810-28e3927df5c6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "id": "8tCrjhtgieUx",
        "outputId": "17c549c9-ce59-49d6-aa33-91b9608643f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1800, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "yoY484YXio4d",
        "outputId": "d346ab4f-5325-49d4-e37d-5dae780dab2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1800 entries, 0 to 1799\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    1800 non-null   object\n",
            " 1   labels  1800 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 28.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**: Split the data into training and testing (80-20)"
      ],
      "metadata": {
        "id": "K_zISEpsoOjs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFnvKJpojo2y"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(dataset, test_size=0.2, random_state=42)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWF1oSY_jglL"
      },
      "source": [
        "**Question 3:** Plot the distribution of lengths of sentences in both training and test set. Extract the max_len value to be used later:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5seZqZp-cWK7",
        "outputId": "348b4346-2d2a-4c19-ae53-a86803a36417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "# plotting histogram for the sentences frequencies\n",
        "plt.hist(train_df[DATA_COLUMN].str.len(), bins=10)\n",
        "plt.hist(test_df[DATA_COLUMN].str.len(), bins=10)\n",
        "plt.title('sentences distributions')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('frequency')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n",
        "\n",
        "max_train=train_df[DATA_COLUMN].str.len().max()\n",
        "max_test=test_df[DATA_COLUMN].str.len().max()\n",
        "print('maximum training length:',max_train)\n",
        "print('maximum testing length:',max_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maximum training length: 864\n",
            "maximum testing length: 683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " We can conclude that the max_len can be chosen to be **256 ** since bert model has 512 tokens it would not eccept text longer than this number ."
      ],
      "metadata": {
        "id": "2Gozk8y2p1os"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULbvRAH24w11"
      },
      "source": [
        "#Training Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by creating the dataset needed for training and testing, we will use the Dataset class from pytorch as our base class.\n",
        "\n",
        "For tokenization, we will be using the autotokenizer from HuggingFace."
      ],
      "metadata": {
        "id": "POaAvq9NtKHl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHazBYgbAugR"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers.data.processors.utils import InputFeatures\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "#define the Dataset class\n",
        "class SADataset(Dataset):\n",
        "  def __init__(self, texts, labels, model_name, max_len, label_map):\n",
        "    #hold the text and reviews inside the dataset class\n",
        "    self.texts = texts\n",
        "    self.labels = labels\n",
        "    self.label_map = label_map\n",
        "    self.tokenizer_name = model_name\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    #returns the length of the dataset\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    # Select the example based on the item ID\n",
        "    text = str(self.texts[item])\n",
        "    label = self.labels[item]\n",
        "\n",
        "    input_dict = self.tokenizer(\n",
        "          text,\n",
        "          add_special_tokens=True,\n",
        "          max_length=self.max_len,\n",
        "          padding = 'max_length',\n",
        "          truncation= True\n",
        "      )\n",
        "\n",
        "    return InputFeatures(input_ids=input_dict[\"input_ids\"],\n",
        "                         token_type_ids=input_dict['token_type_ids'],\n",
        "                         attention_mask=input_dict[\"attention_mask\"],\n",
        "                         label=self.label_map[self.labels[item]])\n",
        "\n",
        "\n",
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4:** Define the evaluation metrics that we will need, including `accuracy_score`, `f1_score`, `precision_score` and `recall_score` from sklearn."
      ],
      "metadata": {
        "id": "5A70UoelxyYO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGPOnvGZRlVT"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    assert len(preds) == len(pred.label_ids)\n",
        " # label check with metrices define\n",
        "    macro_f1 = f1_score(pred.label_ids, preds, average='macro')\n",
        "    macro_f1_pos_neg = f1_score(pred.label_ids, preds, average='binary',labels=[0,1])\n",
        "    macro_precision = precision_score(pred.label_ids, preds, average='macro')\n",
        "    macro_recall = recall_score(pred.label_ids, preds, average='macro')\n",
        "    acc = accuracy_score(pred.label_ids, preds)\n",
        "\n",
        "    return {\n",
        "        'macro_f1': macro_f1,\n",
        "        'macro_f1_pos_neg': macro_f1_pos_neg,\n",
        "        'macro_precision': macro_precision,\n",
        "        'macro_recall': macro_recall,\n",
        "        'accuracy': acc\n",
        "    }\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcjtO-0N0u98"
      },
      "source": [
        "## Preprocess the dataset\n",
        "Let's start by defining the AraBERT preprocessor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbMtdGpB0t3w"
      },
      "source": [
        "from arabert.preprocess import ArabertPreprocessor\n",
        "\n",
        "model_name = 'aubmindlab/bert-base-arabertv02'\n",
        "arabert_prep = ArabertPreprocessor(model_name)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5:** Apply preprocessing for the text column using the arabert preprocessor:"
      ],
      "metadata": {
        "id": "RWKdP_IN1UpM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-wo9pTC0zXT"
      },
      "source": [
        "train_df[DATA_COLUMN] = train_df[DATA_COLUMN].apply(lambda x: arabert_prep.preprocess(x) )\n",
        "test_df[DATA_COLUMN] = test_df[DATA_COLUMN].apply(lambda x: arabert_prep.preprocess(x))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[DATA_COLUMN][:3] # as we see these 3 sentences after preprpcessing using Arabert preprocesser"
      ],
      "metadata": {
        "id": "_ZRPxR73mcTq",
        "outputId": "07842751-4784-4b77-a8aa-d6442de24c5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "832     سبحان الله بحمده عدد خلقه رضى نفسه زنه عرشه مد...\n",
              "836                         سبحان الله مالك السموات الارض\n",
              "1103    قصه جميله جدا تعكس معنى الايمان التمسك بالعقيد...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's extract the label to id map:"
      ],
      "metadata": {
        "id": "GgfXN43X1gWV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDikUkPn2DqE",
        "outputId": "21179de2-0349-4c6a-9de1-ddb5f3394de2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "label_list = list(test_df['labels'].unique())\n",
        "label_map = { v:index for index, v in enumerate(label_list) }\n",
        "print(label_map)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Negative': 0, 'Positive': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6:** Create the train and test SADataset:"
      ],
      "metadata": {
        "id": "1JfEWxXM1nDj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2zr1L_31e5J",
        "outputId": "ecc5cd9b-d9b4-469b-8dba-53db29daf827",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "max_len = 256\n",
        "train_dataset = SADataset(texts=train_df['text'].tolist(),\n",
        "                          labels=train_df['labels'].tolist(),\n",
        "                          model_name=model_name,\n",
        "                          max_len=max_len,\n",
        "                          label_map=label_map)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_dataset = SADataset(texts=test_df['text'].tolist(),\n",
        "                         labels=test_df['labels'].tolist(),\n",
        "                         model_name=model_name,\n",
        "                         max_len=max_len,\n",
        "                         label_map=label_map)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f0Tr_Jr4eAz"
      },
      "source": [
        "# Setup the HuggingFace trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using the `bert-base-arabertv02` from HuggingFace models by Antoun et Al (2020). We can choose other Arabic BERT models by just changing the path here from `https://huggingface.co/models`."
      ],
      "metadata": {
        "id": "vi_EhH9CqH_N"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVUtKhfwiyMZ",
        "outputId": "04f69b4d-f403-441e-829f-6ee7a5f69331",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=len(label_map))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now set up the training arguments, you can more information from https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments"
      ],
      "metadata": {
        "id": "UbLm8trS2NTg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BtOuUXX4JD0"
      },
      "source": [
        "from transformers import Trainer , TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= \"./train\",\n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 5e-5,\n",
        "    fp16 = True,\n",
        "    per_device_train_batch_size = 20, # i try with 16 and 20 to see the difference\n",
        "    per_device_eval_batch_size = 20,\n",
        "    gradient_accumulation_steps = 2,\n",
        "    num_train_epochs= 3, # change the epochs number to 3\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'eval_macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 42\n",
        "  )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ0Kxrs46QI9",
        "outputId": "d9b8625d-826a-401d-abf5-d6cbff0a096d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_args.__dict__"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'output_dir': './train',\n",
              " 'overwrite_output_dir': False,\n",
              " 'do_train': False,\n",
              " 'do_eval': True,\n",
              " 'do_predict': False,\n",
              " 'evaluation_strategy': <IntervalStrategy.EPOCH: 'epoch'>,\n",
              " 'prediction_loss_only': False,\n",
              " 'per_device_train_batch_size': 20,\n",
              " 'per_device_eval_batch_size': 20,\n",
              " 'per_gpu_train_batch_size': None,\n",
              " 'per_gpu_eval_batch_size': None,\n",
              " 'gradient_accumulation_steps': 2,\n",
              " 'eval_accumulation_steps': None,\n",
              " 'eval_delay': 0,\n",
              " 'learning_rate': 5e-05,\n",
              " 'weight_decay': 0.0,\n",
              " 'adam_beta1': 0.9,\n",
              " 'adam_beta2': 0.999,\n",
              " 'adam_epsilon': 1e-08,\n",
              " 'max_grad_norm': 1.0,\n",
              " 'num_train_epochs': 3,\n",
              " 'max_steps': -1,\n",
              " 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>,\n",
              " 'warmup_ratio': 0.0,\n",
              " 'warmup_steps': 0,\n",
              " 'log_level': 'passive',\n",
              " 'log_level_replica': 'warning',\n",
              " 'log_on_each_node': True,\n",
              " 'logging_dir': './train/runs/Jan24_22-46-29_7c3819129a86',\n",
              " 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>,\n",
              " 'logging_first_step': False,\n",
              " 'logging_steps': 500,\n",
              " 'logging_nan_inf_filter': True,\n",
              " 'save_strategy': <IntervalStrategy.EPOCH: 'epoch'>,\n",
              " 'save_steps': 500,\n",
              " 'save_total_limit': None,\n",
              " 'save_safetensors': True,\n",
              " 'save_on_each_node': False,\n",
              " 'no_cuda': False,\n",
              " 'use_cpu': False,\n",
              " 'use_mps_device': False,\n",
              " 'seed': 42,\n",
              " 'data_seed': None,\n",
              " 'jit_mode_eval': False,\n",
              " 'use_ipex': False,\n",
              " 'bf16': False,\n",
              " 'fp16': True,\n",
              " 'fp16_opt_level': 'O1',\n",
              " 'half_precision_backend': 'auto',\n",
              " 'bf16_full_eval': False,\n",
              " 'fp16_full_eval': False,\n",
              " 'tf32': None,\n",
              " 'local_rank': 0,\n",
              " 'ddp_backend': None,\n",
              " 'tpu_num_cores': None,\n",
              " 'tpu_metrics_debug': False,\n",
              " 'debug': [],\n",
              " 'dataloader_drop_last': False,\n",
              " 'eval_steps': None,\n",
              " 'dataloader_num_workers': 0,\n",
              " 'past_index': -1,\n",
              " 'run_name': './train',\n",
              " 'disable_tqdm': False,\n",
              " 'remove_unused_columns': True,\n",
              " 'label_names': None,\n",
              " 'load_best_model_at_end': True,\n",
              " 'metric_for_best_model': 'eval_macro_f1',\n",
              " 'greater_is_better': True,\n",
              " 'ignore_data_skip': False,\n",
              " 'fsdp': [],\n",
              " 'fsdp_min_num_params': 0,\n",
              " 'fsdp_config': {'min_num_params': 0,\n",
              "  'xla': False,\n",
              "  'xla_fsdp_grad_ckpt': False},\n",
              " 'fsdp_transformer_layer_cls_to_wrap': None,\n",
              " 'deepspeed': None,\n",
              " 'label_smoothing_factor': 0.0,\n",
              " 'optim': <OptimizerNames.ADAMW_TORCH: 'adamw_torch'>,\n",
              " 'optim_args': None,\n",
              " 'adafactor': False,\n",
              " 'group_by_length': False,\n",
              " 'length_column_name': 'length',\n",
              " 'report_to': ['tensorboard'],\n",
              " 'ddp_find_unused_parameters': None,\n",
              " 'ddp_bucket_cap_mb': None,\n",
              " 'ddp_broadcast_buffers': None,\n",
              " 'dataloader_pin_memory': True,\n",
              " 'skip_memory_metrics': True,\n",
              " 'use_legacy_prediction_loop': False,\n",
              " 'push_to_hub': False,\n",
              " 'resume_from_checkpoint': None,\n",
              " 'hub_model_id': None,\n",
              " 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>,\n",
              " 'hub_token': None,\n",
              " 'hub_private_repo': False,\n",
              " 'hub_always_push': False,\n",
              " 'gradient_checkpointing': False,\n",
              " 'gradient_checkpointing_kwargs': None,\n",
              " 'include_inputs_for_metrics': False,\n",
              " 'fp16_backend': 'auto',\n",
              " 'push_to_hub_model_id': None,\n",
              " 'push_to_hub_organization': None,\n",
              " 'push_to_hub_token': None,\n",
              " 'mp_parameters': '',\n",
              " 'auto_find_batch_size': False,\n",
              " 'full_determinism': False,\n",
              " 'torchdynamo': None,\n",
              " 'ray_scope': 'last',\n",
              " 'ddp_timeout': 1800,\n",
              " 'torch_compile': False,\n",
              " 'torch_compile_backend': None,\n",
              " 'torch_compile_mode': None,\n",
              " 'dispatch_batches': None,\n",
              " 'split_batches': False,\n",
              " 'include_tokens_per_second': False,\n",
              " 'neftune_noise_alpha': None,\n",
              " 'distributed_state': Distributed environment: NO\n",
              " Num processes: 1\n",
              " Process index: 0\n",
              " Local process index: 0\n",
              " Device: cuda,\n",
              " '_n_gpu': 1,\n",
              " '__cached__setup_devices': device(type='cuda', index=0),\n",
              " 'deepspeed_plugin': None}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Initialize the Trainer and start training:"
      ],
      "metadata": {
        "id": "C7UNtb2J3b8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        " # train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "xjkQbicwsf42",
        "outputId": "9d406b39-196f-4706-f2e3-a5c91d9a8f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [108/108 02:10, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Macro F1 Pos Neg</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.167836</td>\n",
              "      <td>0.930271</td>\n",
              "      <td>0.934726</td>\n",
              "      <td>0.929876</td>\n",
              "      <td>0.930796</td>\n",
              "      <td>0.930556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.139659</td>\n",
              "      <td>0.947006</td>\n",
              "      <td>0.950392</td>\n",
              "      <td>0.946594</td>\n",
              "      <td>0.947550</td>\n",
              "      <td>0.947222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.149207</td>\n",
              "      <td>0.952378</td>\n",
              "      <td>0.956743</td>\n",
              "      <td>0.954375</td>\n",
              "      <td>0.951118</td>\n",
              "      <td>0.952778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=108, training_loss=0.1775768068101671, metrics={'train_runtime': 132.5337, 'train_samples_per_second': 32.595, 'train_steps_per_second': 0.815, 'total_flos': 568319879577600.0, 'train_loss': 0.1775768068101671, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvxxCSpI-yGG"
      },
      "source": [
        "#  Saving the best model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before saving the model, let's change the label2id in the config file, and get the id to label map."
      ],
      "metadata": {
        "id": "qma6qGK1-6rj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPCX0NUt51wS"
      },
      "source": [
        "trainer.model.config.label2id = label_map\n",
        "inv_label_map = { v:k for k, v in label_map.items()}\n",
        "trainer.model.config.id2label = inv_label_map"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1UFwVNs-6Dk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "879195b1-d290-4382-9354-dec4f73dc5d0"
      },
      "source": [
        "#save the model in the folder\n",
        "trainer.save_model(\"best_sa_model\")\n",
        "test_dataset.tokenizer.save_pretrained(\"best_sa_model\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('best_sa_model/tokenizer_config.json',\n",
              " 'best_sa_model/special_tokens_map.json',\n",
              " 'best_sa_model/vocab.txt',\n",
              " 'best_sa_model/added_tokens.json',\n",
              " 'best_sa_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "422JyvSi_n0d"
      },
      "source": [
        "# Loading the model for inference\n",
        "We can use HuggingFace pipelines to load the model for inference:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzTSG6cp_g36"
      },
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\n",
        "        \"sentiment-analysis\",\n",
        "        model = \"best_sa_model\",\n",
        "        device=0, # set device to 0 for CUDA\n",
        "        )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aJegKHL_zjk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9bafe2d-f06b-4442-af32-5fb4349f154d"
      },
      "source": [
        "pipe(\"انا لا احبك\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'Negative', 'score': 0.9820467233657837}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"   الأحلام سوف تتحقق\")"
      ],
      "metadata": {
        "id": "5Sl3tW71-v92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7313e986-8dd3-410c-cb50-c7713533dcc8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'Positive', 'score': 0.9953195452690125}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}